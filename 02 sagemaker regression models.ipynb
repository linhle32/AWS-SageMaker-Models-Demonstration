{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "825c8abf",
   "metadata": {},
   "source": [
    "# SageMaker Models for Regression\n",
    "\n",
    "## Loading the data\n",
    "\n",
    "In this module, we practice with the obesity data again. Each row in the data represents a subject. The data has 16 attributes on different measurements of the subjects such as gender, age, height, other test measurements, and the obesity level. The target is obesity level of each subject which is as follows\n",
    "\n",
    "- ObesityLevel = 1 : Insufficient_Weight\n",
    "- ObesityLevel = 2 : Normal_Weight\n",
    "- ObesityLevel = 3 : Overweight_Level_I\n",
    "- ObesityLevel = 4 : Overweight_Level_II\n",
    "- ObesityLevel = 5 : Obesity_Type_I\n",
    "- ObesityLevel = 6 : Obesity_Type_II\n",
    "- ObesityLevel = 7 : Obesity_Type_III\n",
    "\n",
    "Data preprocessing is just a basic pipeline to impute and standardize numeric data, and encode categorical data. Please refer to the classification notebook first since description in this notebook is minimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53e0f27f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/fsspec/registry.py:272: UserWarning: Your installed version of s3fs is very old and known to cause\n",
      "severe performance issues, see also https://github.com/dask/dask/issues/10276\n",
      "\n",
      "To fix, you should specify a lower version bound on s3fs, or\n",
      "update the current installation.\n",
      "\n",
      "  warnings.warn(s3_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>FamilyHistory</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>ObesityLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>64.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>56.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>77.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   Age  Height  Weight FamilyHistory FAVC  FCVC  NCP       CAEC  \\\n",
       "0  Female  21.0    1.62    64.0           yes   no   2.0  3.0  Sometimes   \n",
       "1  Female  21.0    1.52    56.0           yes   no   3.0  3.0  Sometimes   \n",
       "2    Male  23.0    1.80    77.0           yes   no   2.0  3.0  Sometimes   \n",
       "\n",
       "  SMOKE  CH2O  SCC  FAF  TUE        CALC                 MTRANS  ObesityLevel  \n",
       "0    no   2.0   no  0.0  1.0          no  Public_Transportation             2  \n",
       "1   yes   3.0  yes  3.0  0.0   Sometimes  Public_Transportation             2  \n",
       "2    no   2.0   no  2.0  1.0  Frequently  Public_Transportation             2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_name = 'obesity.csv'\n",
    "data_location = 'your bucket'\n",
    "\n",
    "data = pd.read_csv(data_location + data_name)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacbe880",
   "metadata": {},
   "source": [
    "We will also transform the data at the end to process and upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b718a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['Age','Height','Weight','FCVC','NCP','CH2O','FAF','TUE']\n",
    "cat_cols = ['Gender','FamilyHistory','CAEC','SMOKE','SCC','CALC','MTRANS']\n",
    "target = 'ObesityLevel'\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "traindata, testdata = train_test_split(data, test_size=0.2)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#pipeline for numeric columns\n",
    "num_pipeline = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='median')),\n",
    "    ('standardize', StandardScaler())\n",
    "])\n",
    "\n",
    "#pipeline for class columns\n",
    "cat_pipeline = Pipeline([\n",
    "    ('encode', OneHotEncoder(max_categories=5, handle_unknown='infrequent_if_exist'))\n",
    "])\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#combining\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('numeric', num_pipeline, num_cols),\n",
    "    ('class', cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "train_features = full_pipeline.fit_transform(traindata)\n",
    "test_features = full_pipeline.transform(testdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192b8539",
   "metadata": {},
   "source": [
    "### Process Data for SageMaker\n",
    "\n",
    "Similar to the classification notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a396c922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#further split training data to training and validation\n",
    "trainX, validX, trainY, validY = train_test_split(train_features, traindata[target], test_size=0.2)\n",
    "\n",
    "#reorganize the data in format <label - features>\n",
    "#we add .values to get the numpy data instead of the pandas dataframes\n",
    "import numpy as np\n",
    "traindata = np.concatenate([trainY.values.reshape(-1,1), trainX],axis=1)\n",
    "validdata = np.concatenate([validY.values.reshape(-1,1), validX],axis=1)\n",
    "\n",
    "#generate csv files to upload\n",
    "pd.DataFrame(traindata).to_csv('train.csv', index=False, header=False)\n",
    "pd.DataFrame(validdata).to_csv('validation.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf0c884",
   "metadata": {},
   "source": [
    "Then upload to the designated bucket on S3. You can change prefix to send the data to a different folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7264d5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "sess = sagemaker.Session()                        # get our current SageMaker session\n",
    "bucket = 'lle13-it7143'                           # this should be the name of the bucket we created in module 9\n",
    "prefix = 'obesity'                                # the folder to store your data in the S3 instance\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation/validation.csv')).upload_file('validation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048925a9",
   "metadata": {},
   "source": [
    "## AWS XGBoost\n",
    "\n",
    "### Setting Hyperparameter Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f22d6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker_models import *\n",
    "\n",
    "from sagemaker.parameter import CategoricalParameter, ContinuousParameter, IntegerParameter\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    'eta': ContinuousParameter(0, 1), \n",
    "    'min_child_weight': ContinuousParameter(1, 10),\n",
    "    'alpha': ContinuousParameter(0, 2), \n",
    "    'max_depth': IntegerParameter(1, 10)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbecaa7d",
   "metadata": {},
   "source": [
    "### Build and Train XGBoost Model for Regression\n",
    "\n",
    "You should monitor the training job through SageMaker console to make sure everything runs properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cd9475e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................................................................................!\n"
     ]
    }
   ],
   "source": [
    "#path to training and validation data\n",
    "s3_input_train = sagemaker.TrainingInput(s3_data='s3://{}/{}/train'.format(bucket, prefix), content_type='csv')\n",
    "s3_input_validation = sagemaker.TrainingInput(s3_data='s3://{}/{}/validation'.format(bucket, prefix), content_type='csv')\n",
    "\n",
    "#download model image\n",
    "region = boto3.Session().region_name\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "xgb_cont = get_image_uri(region, 'xgboost', repo_version='1.0-1')\n",
    "\n",
    "#create model\n",
    "role = sagemaker.get_execution_role()\n",
    "xgb = sagemaker.estimator.Estimator(xgb_cont, role, train_instance_count=1, train_instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix), sagemaker_session=sess)\n",
    "\n",
    "#regression parameters\n",
    "xgb.set_hyperparameters(eval_metric='rmse',\n",
    "                        objective='reg:squarederror',\n",
    "                        num_round=100,\n",
    "                        rate_drop=0.1,\n",
    "                        tweedie_variance_power=1.4)\n",
    "\n",
    "#create model tuner\n",
    "xgb_tuner = HyperparameterTuner(xgb, \n",
    "                                objective_metric_name='validation:rmse', \n",
    "                                objective_type='Minimize',\n",
    "                                hyperparameter_ranges=hyperparameter_ranges, \n",
    "                                max_jobs=15, max_parallel_jobs=3)\n",
    "\n",
    "xgb_tuner.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76f5510",
   "metadata": {},
   "source": [
    "### Deploy the Model\n",
    "\n",
    "Deploy the model to an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72cd0a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-01-04 01:03:17 Starting - Found matching resource for reuse\n",
      "2024-01-04 01:03:17 Downloading - Downloading the training image\n",
      "2024-01-04 01:03:17 Training - Training image download completed. Training in progress.\n",
      "2024-01-04 01:03:17 Uploading - Uploading generated training model\n",
      "2024-01-04 01:03:17 Completed - Resource reused by training job: sagemaker-xgboost-240104-0057-012-169a5fb5\n",
      "-----!"
     ]
    }
   ],
   "source": [
    "best_xgboost = xgb_tuner.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge', model_name='xgboost-reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670a7119",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "Like in classification, we need to serialize the test data before sending to the endpoint for prediction. The result also needs some processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cdd356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.base_serializers import CSVSerializer\n",
    "\n",
    "best_xgboost.serializer = CSVSerializer()\n",
    "predictions = best_xgboost.predict(test_features).decode('utf-8') # predict!\n",
    "testY_pred_xgb = np.fromstring(predictions[1:], sep=',') # and turn the prediction into an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69c8d601",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MSE: 0.09298963123856822\n",
      "Testing R2: 0.9772470609653264\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print('Testing MSE:',mean_squared_error(testdata[target], testY_pred_xgb))\n",
    "print('Testing R2:',r2_score(testdata[target], testY_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5d9c35",
   "metadata": {},
   "source": [
    "### Removing Endpoint before Moving on to Linear Learner\n",
    "\n",
    "Remember to remove the endpoint due to the restriction on free-tier account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a755f2fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_xgboost.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb49c167",
   "metadata": {},
   "source": [
    "## AWS Linear Learner\n",
    "\n",
    "Now let's move on to Linear Learner model. Everything is pretty much the same as before\n",
    "\n",
    "### Setting Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "049500b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: 1.0-1.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "from sagemaker_models import *\n",
    "\n",
    "from sagemaker.parameter import CategoricalParameter, ContinuousParameter, IntegerParameter\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"l1\": ContinuousParameter(1e-7, 1, scaling_type=\"Auto\"),\n",
    "    \"wd\": ContinuousParameter(1e-7, 1, scaling_type=\"Auto\"),\n",
    "    \"learning_rate\": ContinuousParameter(1e-5, 1, scaling_type=\"Auto\"),\n",
    "    \"mini_batch_size\": IntegerParameter(100, 500, scaling_type=\"Auto\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00582a48",
   "metadata": {},
   "source": [
    "### Build and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db84b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to training and validation data\n",
    "s3_input_train = sagemaker.TrainingInput(s3_data='s3://{}/{}/train'.format(bucket, prefix), content_type='text/csv')\n",
    "s3_input_validation = sagemaker.TrainingInput(s3_data='s3://{}/{}/validation'.format(bucket, prefix), content_type='text/csv')\n",
    "\n",
    "#download model image\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "region = boto3.Session().region_name\n",
    "ll_cont = get_image_uri(region, 'linear-learner', repo_version='1.0-1')\n",
    "\n",
    "#create model\n",
    "role = sagemaker.get_execution_role()\n",
    "ll = sagemaker.estimator.Estimator(ll_cont, role, train_instance_count=1, train_instance_type='ml.m4.xlarge',\n",
    "                                output_path='s3://{}/{}/output'.format(bucket, prefix), sagemaker_session=sess)\n",
    "\n",
    "#regression parameter\n",
    "ll.set_hyperparameters(predictor_type='regressor')\n",
    "\n",
    "#create model tuner\n",
    "ll_tuner = HyperparameterTuner(ll, \n",
    "                        objective_metric_name='validation:objective_loss', \n",
    "                        objective_type='Minimize',\n",
    "                        hyperparameter_ranges=hyperparameter_ranges, \n",
    "                        max_jobs=15, max_parallel_jobs=3)\n",
    "\n",
    "#send model tuner to SageMaker\n",
    "ll_tuner.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecfcadc",
   "metadata": {},
   "source": [
    "### Deploy the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8df2a582",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-01-04 01:42:22 Starting - Found matching resource for reuse\n",
      "2024-01-04 01:42:22 Downloading - Downloading the training image\n",
      "2024-01-04 01:42:22 Training - Training image download completed. Training in progress.\n",
      "2024-01-04 01:42:22 Uploading - Uploading generated training model\n",
      "2024-01-04 01:42:22 Completed - Resource reused by training job: linear-learner-240104-0135-012-3b69bb75\n",
      "-------!"
     ]
    }
   ],
   "source": [
    "best_ll = ll_tuner.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge', model_name='ll-reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1338a2",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "Similar to Linear Learner for classification, we set a serializer for test data, and process the returned results as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a8160e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "best_ll.serializer = CSVSerializer()\n",
    "predictions = best_ll.predict(test_features).decode('utf-8') # predict!\n",
    "testY_pred_ll = json.loads(predictions)\n",
    "testY_pred_ll = np.array([yh['score'] for yh in testY_pred_ll['predictions']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6635a355",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MSE: 0.19381244170347484\n",
      "Testing R2: 0.9525774797522651\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print('Testing MSE:',mean_squared_error(testdata[target], testY_pred_ll))\n",
    "print('Testing R2:',r2_score(testdata[target], testY_pred_ll))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c8e4c2",
   "metadata": {},
   "source": [
    "<h3>Final Clean up</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93905be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '41dd8570-08cc-4197-b360-5f68b73fbba9',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '41dd8570-08cc-4197-b360-5f68b73fbba9',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Thu, 04 Jan 2024 01:49:33 GMT'},\n",
       "  'RetryAttempts': 2}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ll.delete_endpoint(delete_endpoint_config=True)\n",
    "\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "# delete model\n",
    "sagemaker_client.delete_model(ModelName='xgboost-reg')\n",
    "sagemaker_client.delete_model(ModelName='ll-reg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
